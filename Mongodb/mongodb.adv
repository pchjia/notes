1. 在mongodb中使用js语法
    > for (var i=0; i<10000; i++) {
            db.test.insert({_id: i+1, title: 'hello world!', content: 'this is the ' + i+1 + 'th article.'});
        };
    > db.test.find().count();

2. 游标操作 cursor
    游标不是查询结果，而是查询的接口。通过游标，可以逐条读取，类似文件流。
    var cursor = db.collection_name.find(query, projection)
    cursor.hasNext()    # 判断是否有下一项
    cursor.next()       # 获取下一项，bson对象
    printjson(cursor.next()) # 以json格式打印出来

    forEach 回调函数
        var cursor = db.collection_name.find(query, projection)
        var detail = finction(obj) {
            print('your id is ' + obj_id);
            printjson(obj);
        }
        cursor.forEach(detail);

        <=>
        cursor.forEach(function(obj) printjson(obj))
    分页中的使用
        查到10000行，跳过100页，取10行
        mysql: limit offset, N
        mongodb: skip() limit()
        var cursor = db.test.find().skip(100*10).limit(10)        # 跳过前100页，每页10行，再取10行
        <=> db.test.find().skip(100*10).limit(10)

    toArray() 将结果以数组形式返回，此操作会把所有的行立即以对象的形式组织在内存中，一般取少数几行时用此功能
        var cursor = db.test.find()
        curson.toArray()

3. 索引 加索引会提高查询速度，也会减慢插入速度，默认是用btree来组织索引文件
    db.collection_name.ensureIndex({a: 1/-1})                       # 将a列按升序/降序建立索引，不存在的列建立索引值为null
    db.collection_name.getIndexes()                                 # 查看当前索引

    db.collection_name.createIndex({a: 1})                          # 创建索引
    db.collection.createIndex( { a: 1, b: 1, c: 1 } )               # 创建多列索引
    db.collection.createIndex( { a: 1 }, { unique: true } )         # 创建唯一索引，取值不重复的列
    db.collection.createIndex( { a: 1, b: 1 }, { unique: true } )   # 创建多列的唯一索引

    db.collection.createIndex(
       { a: 1 },
       { partialFilterExpression: { b: { $gt: 5 } } }
    )                                       # 创建局部索引

    db.collection.createIndex( { a: 1 }, { sparse: true } )         # 创建稀疏索引，不含此列不建立索引
    db.collection.createIndex( { _id: "hashed" } )                  # 创建hash索引
    db.collection.createIndex({'a.b':1})    # 子文档加索引，用点表示引用子文档

    db.collection.dropIndex({a: -1})        # 删除索引
    db.collection.dropIndexes()             # 删除所有索引

    修改索引需要删除索引并重新建立索引

    db.accounts.reIndex()   # 重建索引，减少碎片，集合经过一段时间的修改后，表中的文件容易出现空洞，查询效率不高


注明:
    子文档查询：
        db.user.insert({name: 'pc', subject: {math: 90, english: 90}})
        db.user.find({'subject.math': {$exists: 1}}, {_id: 0,'subject.math':1})

4. 用户管理
    mongodb中有一个admin数据库
    mongodb中用户以数据库为单位，每个数据库都有自己的管理员，先在admin中建立超级管理员，再管理其他数据库
    启动mongodb时需要加上--auth选项

    db.createUser({ user: "<name>",
      pwd: "<cleartext password>",
      customData: { <any information> },
      roles: [
        { role: "<role>", db: "<database>" } | "<role>",
        ...
      ]
    })

    db.createUser({user: 'pchjia', pwd: 'jia9692', roles: []})
    db.createUser({user: 'pchjia', pwd: 'jia9692', roles: [{role: 'clusterAdmin', db: 'admin'}, {role: 'readAnyDatabase', db: 'admin'}, 'readWrite', 'dbOwner']})
    db.addUser({ user: "myadmin", pwd: "1234", roles: ["userAdminAnyDatabase"] })
    use admin
    db.auth('user_name', 'password')

    see: built-in roles
        https://docs.mongodb.org/manual/reference/built-in-roles/#database-administration-roles

    db.dropUser('user_name')

    db.revokeRolesFromUser(
        "reportsUser",
        [
          { role: "readWrite", db: "accounts" }
        ]
    )

    db.grantRolesToUser(
        "reportsUser",
        [
          { role: "read", db: "accounts" }
        ]
    )

    db.changeUserPassword("user_name", "new_password")

5. 备份与恢复
    mongo --host host --port port --username username --password password

    mongoexport --help
        -u, --username=<username>                       username for authentication
        -p, --password=<password>                       password for authentication
          --authenticationDatabase=<database-name>    database that holds the user's credentials
          --authenticationMechanism=<mechanism>       authentication mechanism to use
        -d, --db=<database-name>                        database to use
        -c, --collection=<collection-name>              collection to use
        -f, --fields=<field>[,<field>]*                 comma separated list of field names (required for exporting CSV) e.g. -f "name,age"
          --fieldFile=<filename>                      file with field names - 1 per line
          --type=<type>                               the output format, either json or csv (defaults to 'json')
        -o, --out=<filename>                            output file; if not specified, stdout is used
          --jsonArray                                 output to a JSON array rather than one object per line
          --pretty                                    output JSON formatted to be human-readable
          --csv                                       csv file, 便于和传统数据库交换数据
        -q, --query=<json>                              query filter, as a JSON string, e.g., '{x:{$gt:1}}'
          --queryFile=<filename>                      path to a file containing a query filter (JSON)

        mongoexport -d test -c test -o test.json

    mongoimport --help
        -u, --username=<username>                       username for authentication
        -p, --password=<password>                       password for authentication
          --authenticationDatabase=<database-name>    database that holds the user's credentials
          --authenticationMechanism=<mechanism>       authentication mechanism to use
        -d, --db=<database-name>                        database to use
        -c, --collection=<collection-name>              collection to use
        -f, --fields=<field>[,<field>]*                 comma separated list of field names, e.g. -f name,age
          --fieldFile=<filename>                      file with field names - 1 per line
          --file=<filename>                           file to import from; if not specified, stdin is used
          --headerline                                use first line in input source as the field list (CSV and TSV only)
          --jsonArray                                 treat input source as a JSON array
          --type=<type>                               input format to import: json, csv, or tsv (defaults to 'json')

          --drop                                      drop collection before inserting documents
          --ignoreBlanks                              ignore fields with empty values in CSV and TSV
          --maintainInsertionOrder                    insert documents in the order of their appearance in the input source
        -j, --numInsertionWorkers=<number>              number of insert operations to run concurrently (defaults to 1)
          --stopOnError                               stop importing at first insert/upsert error
          --upsert                                    insert or update objects that already exist
          --upsertFields=<field>[,<field>]*           comma-separated fields for the query part of the upsert
          --writeConcern=<write-concern-specifier>    write concern options e.g. --writeConcern majority, --writeConcern '{w: 3,
                                                  wtimeout: 500, fsync: true, j: true}' (defaults to 'majority')

        mongoimport -d test -c fun -f filename --type=json 

    导出二进制可以保留索引，用于备份和回复。导出json用于数据库之间传递数据
        mongodump -d database -c collection
        mongorestore -d database -c collection --dir=/path

6. Replication 复制集，提高可用性。HA
    共同维护相同的内容

    mkdir -p /data/r0 /data/r1 /data/r2 /var/log/
    # 声明属于的复制集
    mongod --port 27017 --dbpath /data/r0 --logpath /var/log/mongodbr0.log --smallfiles --replSet rsa --fork --auth 
    mongod --port 27018 --dbpath /data/r1 --logpath /var/log/mongodbr1.log --smallfiles --replSet rsa --fork --auth 
    mongod --port 27019 --dbpath /data/r2 --logpath /var/log/mongodbr2.log --smallfiles --replSet rsa --fork --auth 

    # 配置文件
    var rsconf = {
      _id: 'rsa',
      members: [{_id: 0, host: 'ip:port'}, {_id: 1, host: 'ip:port'}, {_id: 2, host: 'ip:port'}]
    }

    # 初始化
    rs.initiate(rsconf)
    rs.status()
    rs.reconfig(rsconf)
    rs.add('ip:port')       # 添加节点
    rs.remove('ip:port')    # 删除节点

    # slave节点默认不许读写，执行下述命令即可
    rs.slaveOk()


